{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:22:01.182299Z",
     "iopub.status.busy": "2025-04-07T16:22:01.182111Z",
     "iopub.status.idle": "2025-04-07T16:22:26.979122Z",
     "shell.execute_reply": "2025-04-07T16:22:26.978288Z",
     "shell.execute_reply.started": "2025-04-07T16:22:01.182281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pretrain-ms2/pretrained_data.csv\n",
      "/kaggle/input/tokenizer/primera-tokenizer/merges.txt\n",
      "/kaggle/input/tokenizer/primera-tokenizer/tokenizer.json\n",
      "/kaggle/input/tokenizer/primera-tokenizer/vocab.json\n",
      "/kaggle/input/tokenizer/primera-tokenizer/tokenizer_config.json\n",
      "/kaggle/input/tokenizer/primera-tokenizer/special_tokens_map.json\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/config.json\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/trainer_state.json\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/training_args.bin\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/scheduler.pt\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/model.safetensors\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/optimizer.pt\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/rng_state.pth\n",
      "/kaggle/input/primera-ckp/checkpoint-3024/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import LEDConfig,LEDForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from nltk import sent_tokenize\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import random\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "input_dir=\"/kaggle/input/\"\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T04:07:46.835425Z",
     "iopub.status.busy": "2025-04-06T04:07:46.835144Z",
     "iopub.status.idle": "2025-04-06T04:07:46.916369Z",
     "shell.execute_reply": "2025-04-06T04:07:46.915658Z",
     "shell.execute_reply.started": "2025-04-06T04:07:46.835403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:25:10.292191Z",
     "iopub.status.busy": "2025-04-07T16:25:10.291747Z",
     "iopub.status.idle": "2025-04-07T16:25:10.573934Z",
     "shell.execute_reply": "2025-04-07T16:25:10.573290Z",
     "shell.execute_reply.started": "2025-04-07T16:25:10.292164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(input_dir+\"tokenizer/primera-tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:25:12.584330Z",
     "iopub.status.busy": "2025-04-07T16:25:12.584051Z",
     "iopub.status.idle": "2025-04-07T16:25:28.716766Z",
     "shell.execute_reply": "2025-04-07T16:25:28.715976Z",
     "shell.execute_reply.started": "2025-04-07T16:25:12.584309Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncated_docs</th>\n",
       "      <th>selected_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[Improved Cell Survival and Paracrine Capacit...</td>\n",
       "      <td>[(4, 0), (3, 4), (4, 3), (3, 1), (3, 7), (4, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[A comparison of continuous intravenous epopr...</td>\n",
       "      <td>[(0, 2), (0, 5), (1, 0), (1, 6), (0, 8), (1, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Relationship of TIMI myocardial perfusion gr...</td>\n",
       "      <td>[(0, 2), (0, 5), (2, 2), (1, 0), (1, 6), (2, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[Effect of cessation interventions on hookah ...</td>\n",
       "      <td>[(3, 4), (3, 1), (0, 2), (0, 5), (2, 2), (1, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[The Arizona Sexual Experiences Scale: a vali...</td>\n",
       "      <td>[(0, 2), (0, 5), (1, 0), (0, 8), (1, 3), (0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      truncated_docs  \\\n",
       "0  [[Improved Cell Survival and Paracrine Capacit...   \n",
       "1  [[A comparison of continuous intravenous epopr...   \n",
       "2  [[Relationship of TIMI myocardial perfusion gr...   \n",
       "3  [[Effect of cessation interventions on hookah ...   \n",
       "4  [[The Arizona Sexual Experiences Scale: a vali...   \n",
       "\n",
       "                                      selected_sents  \n",
       "0  [(4, 0), (3, 4), (4, 3), (3, 1), (3, 7), (4, 6...  \n",
       "1  [(0, 2), (0, 5), (1, 0), (1, 6), (0, 8), (1, 3...  \n",
       "2  [(0, 2), (0, 5), (2, 2), (1, 0), (1, 6), (2, 5...  \n",
       "3  [(3, 4), (3, 1), (0, 2), (0, 5), (2, 2), (1, 0...  \n",
       "4  [(0, 2), (0, 5), (1, 0), (0, 8), (1, 3), (0, 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_df=pd.read_csv(input_dir+\"pretrain-ms2/pretrained_data.csv\")\n",
    "pretrain_df[\"truncated_docs\"] = pretrain_df[\"truncated_docs\"].apply(ast.literal_eval)\n",
    "pretrain_df[\"selected_sents\"] = pretrain_df[\"selected_sents\"].apply(ast.literal_eval)\n",
    "pretrain_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide into train and eval datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:25:46.315567Z",
     "iopub.status.busy": "2025-04-07T16:25:46.315252Z",
     "iopub.status.idle": "2025-04-07T16:25:46.328203Z",
     "shell.execute_reply": "2025-04-07T16:25:46.327264Z",
     "shell.execute_reply.started": "2025-04-07T16:25:46.315541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train df:  11347\n",
      "Length of val df:  2837\n"
     ]
    }
   ],
   "source": [
    "train_df,val_df=train_test_split(pretrain_df,test_size=0.2,shuffle=True,random_state=40)\n",
    "train_df.reset_index(drop=True,inplace=True)\n",
    "val_df.reset_index(drop=True,inplace=True)\n",
    "print(\"Length of train df: \", len(train_df))\n",
    "print(\"Length of val df: \", len(val_df) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:25:47.991564Z",
     "iopub.status.busy": "2025-04-07T16:25:47.991288Z",
     "iopub.status.idle": "2025-04-07T16:25:48.000052Z",
     "shell.execute_reply": "2025-04-07T16:25:47.999121Z",
     "shell.execute_reply.started": "2025-04-07T16:25:47.991543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH=4096\n",
    "MAX_OUTPUT_LENGTH=512\n",
    "NON_MASK_RATIO=0.5\n",
    "def get_src_tgt_and_mask(truncated_docs, selected_sents,tokenizer,max_len_input,max_len_output,non_mask_ratio):\n",
    "    \"\"\"\n",
    "    Get source and tgt\n",
    "\n",
    "    Args:\n",
    "        truncated_docs (list of list of str): list of documents with sentences.\n",
    "        selected_sents (list of (doc_idx, sent_idx)): Indices of sentences to mask.\n",
    "\n",
    "    Returns:\n",
    "        Src: the cluster with masked salient sentences\n",
    "        Target: The masked salient sentences\n",
    "    \"\"\"\n",
    "    non_mask_sents = random.sample(\n",
    "            list(selected_sents), int(len(selected_sents) * non_mask_ratio)\n",
    "        )\n",
    "    masked_docs = [doc.copy() for doc in truncated_docs] \n",
    "    tgt=[]\n",
    "    for doc_idx, sent_idx in selected_sents:\n",
    "        tgt.append(truncated_docs[doc_idx][sent_idx])\n",
    "        if (doc_idx,sent_idx) in non_mask_sents: \n",
    "            continue\n",
    "        masked_docs[doc_idx][sent_idx] = tokenizer.mask_token\n",
    "    src=\"<doc-sep>\".join([\" \".join(doc) for doc in masked_docs])\n",
    "    src=tokenizer(src,max_length=max_len_input,padding=\"max_length\",truncation=True)\n",
    "    tgt=\" \".join(tgt)\n",
    "    tgt=tokenizer(tgt,max_length=max_len_output,padding=\"max_length\",truncation=True)\n",
    "    input_ids=src.input_ids\n",
    "    global_attention_mask=[0 for _ in range(len(input_ids))]\n",
    "    global_attention_mask[input_ids==tokenizer.vocab[\"<doc-sep>\"]]=1\n",
    "    global_attention_mask[0]=1\n",
    "    labels=tgt.input_ids\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels] \n",
    "    return {\n",
    "        \"input_ids\":torch.tensor(input_ids,dtype=torch.long),\n",
    "        \"attention_mask\":torch.tensor(src.attention_mask,dtype=torch.long),\n",
    "        \"global_attention_mask\":torch.tensor(global_attention_mask,dtype=torch.long),\n",
    "        \"labels\":torch.tensor(labels,dtype=torch.long)\n",
    "    }\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self,data,tokenizer,max_input_len=4096,max_output_len=512,non_mask_ratio=0.5):\n",
    "        self.data=data\n",
    "        self.max_input_len=max_input_len\n",
    "        self.max_output_len=max_output_len\n",
    "        self.tokenizer=tokenizer\n",
    "        self.non_mask_ratio=non_mask_ratio\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        row=self.data.loc[index]\n",
    "        data=get_src_tgt_and_mask(row[\"truncated_docs\"],row[\"selected_sents\"],self.tokenizer,self.max_input_len,\n",
    "                          self.max_output_len,self.non_mask_ratio)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:25:51.969735Z",
     "iopub.status.busy": "2025-04-07T16:25:51.969390Z",
     "iopub.status.idle": "2025-04-07T16:25:51.974887Z",
     "shell.execute_reply": "2025-04-07T16:25:51.974145Z",
     "shell.execute_reply.started": "2025-04-07T16:25:51.969678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset:  11347\n",
      "Length of val dataset:  2837\n"
     ]
    }
   ],
   "source": [
    "train_dataset=PretrainDataset(train_df,tokenizer,MAX_INPUT_LENGTH,MAX_OUTPUT_LENGTH,NON_MASK_RATIO)\n",
    "val_dataset=PretrainDataset(val_df,tokenizer,MAX_INPUT_LENGTH,MAX_OUTPUT_LENGTH,NON_MASK_RATIO)\n",
    "print(\"Length of train dataset: \", len(train_dataset))\n",
    "print(\"Length of val dataset: \", len(val_dataset) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:26:44.001803Z",
     "iopub.status.busy": "2025-04-07T16:26:44.001464Z",
     "iopub.status.idle": "2025-04-07T16:26:54.533933Z",
     "shell.execute_reply": "2025-04-07T16:26:54.532774Z",
     "shell.execute_reply.started": "2025-04-07T16:26:44.001774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#BASE_MODEL_PATH=\"allenai/led-base-16384\"\n",
    "BASE_MODEL_PATH=\"allenai/PRIMERA\"\n",
    "config = LEDConfig.from_pretrained(BASE_MODEL_PATH)\n",
    "model = LEDForConditionalGeneration.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    config=config,\n",
    ")\n",
    "#resize vocab size of model\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.max_decoder_position_embeddings=512\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:27:16.416843Z",
     "iopub.status.busy": "2025-04-07T16:27:16.416455Z",
     "iopub.status.idle": "2025-04-07T16:27:17.619418Z",
     "shell.execute_reply": "2025-04-07T16:27:17.618771Z",
     "shell.execute_reply.started": "2025-04-07T16:27:16.416806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size=3\n",
    "num_devices=torch.cuda.device_count()\n",
    "batch_size_per_device=batch_size//num_devices\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True, \n",
    "    per_device_train_batch_size=batch_size_per_device,\n",
    "    per_device_eval_batch_size=batch_size_per_device,\n",
    "    output_dir=\"./pretrained-primera\",\n",
    "    logging_dir=\"./logs/pretrain/\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_total_limit=1,\n",
    "    #load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"eval_loss\",\n",
    "    #greater_is_better=False,\n",
    "    gradient_accumulation_steps=5,\n",
    "    num_train_epochs=12,\n",
    "    max_grad_norm=1.0,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=5000,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    report_to=\"tensorboard\",\n",
    "    run_name=\"pretraining_primera\",\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "# Set log directory (change if needed)\n",
    "log_dir = \"./logs\"\n",
    "\n",
    "# Start TensorBoard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:27:21.747308Z",
     "iopub.status.busy": "2025-04-07T16:27:21.747023Z",
     "iopub.status.idle": "2025-04-07T16:27:22.770681Z",
     "shell.execute_reply": "2025-04-07T16:27:22.769493Z",
     "shell.execute_reply.started": "2025-04-07T16:27:21.747286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:28:25.350610Z",
     "iopub.status.busy": "2025-04-07T16:28:25.350257Z",
     "iopub.status.idle": "2025-04-07T16:28:25.535905Z",
     "shell.execute_reply": "2025-04-07T16:28:25.534900Z",
     "shell.execute_reply.started": "2025-04-07T16:28:25.350579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: missing end signature--probably not a zip file (did you\n",
      "\tzip warning: remember to use binary mode when you transferred it?)\n",
      "\tzip warning: (if you are trying to read a damaged archive try -F)\n",
      "\n",
      "zip error: Zip file structure invalid (folder.zip)\n"
     ]
    }
   ],
   "source": [
    "!zip -r folder.zip ./pretrained-primera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T16:24:57.257425Z",
     "iopub.status.busy": "2025-04-07T16:24:57.257127Z",
     "iopub.status.idle": "2025-04-07T16:24:57.263281Z",
     "shell.execute_reply": "2025-04-07T16:24:57.262492Z",
     "shell.execute_reply.started": "2025-04-07T16:24:57.257404Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='folder.zip' target='_blank'>folder.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/folder.zip"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'folder.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/kaggle/working/pretrained-primera/checkpoint-2000\"  # Replace with your folder path\n",
    "os.system(f\"rm -rf {folder_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7004530,
     "sourceId": 11216752,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7005158,
     "sourceId": 11217595,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7005170,
     "sourceId": 11217612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
