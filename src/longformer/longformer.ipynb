{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8f4674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:20.267931Z",
     "iopub.status.busy": "2025-05-17T21:41:20.267600Z",
     "iopub.status.idle": "2025-05-17T21:41:46.892349Z",
     "shell.execute_reply": "2025-05-17T21:41:46.891431Z"
    },
    "papermill": {
     "duration": 26.630601,
     "end_time": "2025-05-17T21:41:46.894001",
     "exception": false,
     "start_time": "2025-05-17T21:41:20.263400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import LEDForConditionalGeneration\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoTokenizer\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss,DataParallel\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7464e208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:46.901334Z",
     "iopub.status.busy": "2025-05-17T21:41:46.900783Z",
     "iopub.status.idle": "2025-05-17T21:41:46.985146Z",
     "shell.execute_reply": "2025-05-17T21:41:46.984366Z"
    },
    "papermill": {
     "duration": 0.089081,
     "end_time": "2025-05-17T21:41:46.986435",
     "exception": false,
     "start_time": "2025-05-17T21:41:46.897354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4713ba5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:46.993183Z",
     "iopub.status.busy": "2025-05-17T21:41:46.992900Z",
     "iopub.status.idle": "2025-05-17T21:41:46.996050Z",
     "shell.execute_reply": "2025-05-17T21:41:46.995302Z"
    },
    "papermill": {
     "duration": 0.007791,
     "end_time": "2025-05-17T21:41:46.997388",
     "exception": false,
     "start_time": "2025-05-17T21:41:46.989597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8186670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:47.003690Z",
     "iopub.status.busy": "2025-05-17T21:41:47.003469Z",
     "iopub.status.idle": "2025-05-17T21:41:47.006852Z",
     "shell.execute_reply": "2025-05-17T21:41:47.006067Z"
    },
    "papermill": {
     "duration": 0.007811,
     "end_time": "2025-05-17T21:41:47.008006",
     "exception": false,
     "start_time": "2025-05-17T21:41:47.000195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    tokenizer_save_path = \"allenai/led-base-16384\"\n",
    "    model_save_path = \"allenai/led-base-16384\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_save_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_save_path)\n",
    "    return tokenizer,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d9d592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:47.014300Z",
     "iopub.status.busy": "2025-05-17T21:41:47.014040Z",
     "iopub.status.idle": "2025-05-17T21:41:52.327663Z",
     "shell.execute_reply": "2025-05-17T21:41:52.326733Z"
    },
    "papermill": {
     "duration": 5.318046,
     "end_time": "2025-05-17T21:41:52.328872",
     "exception": false,
     "start_time": "2025-05-17T21:41:47.010826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f254eec4189c4dee9694f39577a1c48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abea01b54a814e03ba47caec37d1789d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f8ca0cd70f496d82aaec05c307d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4f5a53a7f249b0b952721b52d7cc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9836e2edd7b647d6b2e8c96d4b1f22da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a962bbb31b624ad59a4887fbe0f14f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262dd4afb4764a8eab47874fda6427db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer,model= load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a576df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:52.338352Z",
     "iopub.status.busy": "2025-05-17T21:41:52.338040Z",
     "iopub.status.idle": "2025-05-17T21:41:52.341501Z",
     "shell.execute_reply": "2025-05-17T21:41:52.340846Z"
    },
    "papermill": {
     "duration": 0.00983,
     "end_time": "2025-05-17T21:41:52.342722",
     "exception": false,
     "start_time": "2025-05-17T21:41:52.332892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOC_SEP_ = \"<doc-sep>\"\n",
    "docsep_token_id = tokenizer.convert_tokens_to_ids(DOC_SEP_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a091408d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:41:52.350318Z",
     "iopub.status.busy": "2025-05-17T21:41:52.350038Z",
     "iopub.status.idle": "2025-05-17T21:42:09.261281Z",
     "shell.execute_reply": "2025-05-17T21:42:09.259993Z"
    },
    "papermill": {
     "duration": 16.916722,
     "end_time": "2025-05-17T21:42:09.262940",
     "exception": false,
     "start_time": "2025-05-17T21:41:52.346218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: evaluate\r\n",
      "Successfully installed evaluate-0.4.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge-score) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge-score) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=20737ceded97a647c8b3c5a51c5defda8d26ba1bcf487bf19d1e5d59cf70a570\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting bert_score\r\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\r\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.29.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\r\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: bert_score\r\n",
      "Successfully installed bert_score-0.3.13\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate\n",
    "%pip install rouge-score\n",
    "%pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e722f2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:09.274597Z",
     "iopub.status.busy": "2025-05-17T21:42:09.274321Z",
     "iopub.status.idle": "2025-05-17T21:42:10.704751Z",
     "shell.execute_reply": "2025-05-17T21:42:10.704116Z"
    },
    "papermill": {
     "duration": 1.437471,
     "end_time": "2025-05-17T21:42:10.706071",
     "exception": false,
     "start_time": "2025-05-17T21:42:09.268600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc74d71124224362be2c6966bf0e289f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d1c03e36fa491c8bfa8993ff2b24e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load('bertscore')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "    pred_ids[pred_ids == -100] = tokenizer.pad_token_id\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str\n",
    "    )\n",
    "    \n",
    "    bertscore_output = bertscore.compute(\n",
    "        predictions=pred_str, references=label_str, lang='en', \n",
    "    )\n",
    "    \n",
    "    bertscore_output = {a:sum(x)/len(x) for a,x in bertscore_output.items() if a in ['precision', 'recall', 'f1']}\n",
    "    \n",
    "    final_output = {**rouge_output, **bertscore_output}\n",
    "\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d11f233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:10.717680Z",
     "iopub.status.busy": "2025-05-17T21:42:10.717463Z",
     "iopub.status.idle": "2025-05-17T21:42:10.722723Z",
     "shell.execute_reply": "2025-05-17T21:42:10.722127Z"
    },
    "papermill": {
     "duration": 0.012206,
     "end_time": "2025-05-17T21:42:10.723946",
     "exception": false,
     "start_time": "2025-05-17T21:42:10.711740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Medical_Dataset(Dataset):\n",
    "    def __init__(self,tokenizer:AutoTokenizer,train_data,train_label):\n",
    "        self.data = train_data\n",
    "        self.label = train_label\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.label.shape[0]\n",
    "    \n",
    "    def __getitem__(self,id):\n",
    "        sentence = self.data.at[id,'Abstracts']\n",
    "        target = self.label.at[id,'Target']\n",
    "        encoding = self.tokenizer(sentence, return_tensors='pt', truncation=True, max_length=4096)\n",
    "        target_encoding = self.tokenizer(target, return_tensors='pt', truncation=True, max_length=1024)\n",
    "        global_attention_mask = [[1 if y in [tokenizer.cls_token_id, docsep_token_id] else 0 for y in x]\n",
    "                                                 for x in encoding['input_ids']]\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0), # Squeeze to remove the extra dimension\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': target_encoding['input_ids'].squeeze(0),\n",
    "            'global_attention_mask': torch.tensor(np.array(global_attention_mask)).squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97898149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:10.734861Z",
     "iopub.status.busy": "2025-05-17T21:42:10.734657Z",
     "iopub.status.idle": "2025-05-17T21:42:10.737583Z",
     "shell.execute_reply": "2025-05-17T21:42:10.736983Z"
    },
    "papermill": {
     "duration": 0.009662,
     "end_time": "2025-05-17T21:42:10.738786",
     "exception": false,
     "start_time": "2025-05-17T21:42:10.729124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f842578",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:10.749542Z",
     "iopub.status.busy": "2025-05-17T21:42:10.749331Z",
     "iopub.status.idle": "2025-05-17T21:42:15.274397Z",
     "shell.execute_reply": "2025-05-17T21:42:15.273355Z"
    },
    "papermill": {
     "duration": 4.531962,
     "end_time": "2025-05-17T21:42:15.275817",
     "exception": false,
     "start_time": "2025-05-17T21:42:10.743855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-d7b3087c593e>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cochrane_train_input[\"Abstract\"].fillna(\"\",inplace = True)\n",
      "<ipython-input-11-d7b3087c593e>:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cochrane_train_input = cochrane_train_input.groupby('ReviewID').apply(lambda group:\n",
      "<ipython-input-11-d7b3087c593e>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cochrane_dev_input[\"Abstract\"].fillna(\"\",inplace = True)\n",
      "<ipython-input-11-d7b3087c593e>:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cochrane_dev_input = cochrane_dev_input.groupby('ReviewID').apply(lambda group:\n"
     ]
    }
   ],
   "source": [
    "cochrane_train_input = pd.read_csv(\"/kaggle/input/mslr2022/mslr_data/cochrane/train-inputs.csv\")\n",
    "cochrane_train_input[\"Abstract\"].fillna(\"\",inplace = True)\n",
    "cochrane_train_input = cochrane_train_input.groupby('ReviewID').apply(lambda group:\n",
    "    \"\".join([f\"{row['Title']}{DOC_SEP_}{row['Abstract']}{DOC_SEP_}\" for index, row in group.iterrows()])\n",
    ").reset_index(name=\"Abstracts\")\n",
    "cochrane_train_label = pd.read_csv(\"/kaggle/input/mslr2022/mslr_data/cochrane/train-targets.csv\")\n",
    "\n",
    "cochrane_train_input.sort_values(by='ReviewID', inplace=True)\n",
    "cochrane_train_input.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cochrane_train_label.drop_duplicates(subset=['ReviewID'], keep='first', inplace=True)\n",
    "cochrane_train_label.sort_values(by='ReviewID', inplace=True)\n",
    "cochrane_train_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# cochrane_train_input = cochrane_train_input.iloc[0:2,:]\n",
    "# cochrane_train_label = cochrane_train_label.iloc[0:2,:]\n",
    "\n",
    "train_dataset = Medical_Dataset(tokenizer,cochrane_train_input,cochrane_train_label)\n",
    "\n",
    "\n",
    "cochrane_dev_input = pd.read_csv(\"/kaggle/input/mslr2022/mslr_data/cochrane/dev-inputs.csv\")\n",
    "cochrane_dev_input[\"Abstract\"].fillna(\"\",inplace = True)\n",
    "cochrane_dev_input = cochrane_dev_input.groupby('ReviewID').apply(lambda group:\n",
    "    \"\".join([f\"{row['Title']}{DOC_SEP_}{row['Abstract']}{DOC_SEP_}\" for index, row in group.iterrows()])\n",
    ").reset_index(name=\"Abstracts\")\n",
    "cochrane_dev_label = pd.read_csv(\"/kaggle/input/mslr2022/mslr_data/cochrane/dev-targets.csv\")\n",
    "\n",
    "cochrane_dev_input.sort_values(by='ReviewID', inplace=True)\n",
    "cochrane_dev_input.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cochrane_dev_label.drop_duplicates(subset=['ReviewID'], keep='first', inplace=True)\n",
    "cochrane_dev_label.sort_values(by='ReviewID', inplace=True)\n",
    "cochrane_dev_label.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# cochrane_dev_input = cochrane_dev_input.iloc[0:2,:]\n",
    "# cochrane_dev_label = cochrane_dev_label.iloc[0:2,:]\n",
    "\n",
    "valid_dataset = Medical_Dataset(tokenizer,cochrane_dev_input,cochrane_dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b8c16e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:15.288263Z",
     "iopub.status.busy": "2025-05-17T21:42:15.287989Z",
     "iopub.status.idle": "2025-05-17T21:42:15.784323Z",
     "shell.execute_reply": "2025-05-17T21:42:15.783580Z"
    },
    "papermill": {
     "duration": 0.504137,
     "end_time": "2025-05-17T21:42:15.785932",
     "exception": false,
     "start_time": "2025-05-17T21:42:15.281795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-12-f4b5f11747cc>:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',      \n",
    "    num_train_epochs=epochs,            \n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=2,  \n",
    "    warmup_steps=500,              \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    predict_with_generate=True,\n",
    "    learning_rate=learning_rate,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8678e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T21:42:15.798213Z",
     "iopub.status.busy": "2025-05-17T21:42:15.797911Z",
     "iopub.status.idle": "2025-05-18T08:00:27.175233Z",
     "shell.execute_reply": "2025-05-18T08:00:27.174489Z"
    },
    "papermill": {
     "duration": 37091.38451,
     "end_time": "2025-05-18T08:00:27.176409",
     "exception": false,
     "start_time": "2025-05-17T21:42:15.791899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "Input ids are automatically padded from 1134 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18760' max='18760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18760/18760 10:18:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.988400</td>\n",
       "      <td>2.767788</td>\n",
       "      <td>0.194913</td>\n",
       "      <td>0.048368</td>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.151579</td>\n",
       "      <td>0.888284</td>\n",
       "      <td>0.839670</td>\n",
       "      <td>0.863116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.718600</td>\n",
       "      <td>2.684290</td>\n",
       "      <td>0.194397</td>\n",
       "      <td>0.048051</td>\n",
       "      <td>0.149921</td>\n",
       "      <td>0.151134</td>\n",
       "      <td>0.885977</td>\n",
       "      <td>0.838755</td>\n",
       "      <td>0.861535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.561200</td>\n",
       "      <td>2.643972</td>\n",
       "      <td>0.185898</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.142028</td>\n",
       "      <td>0.142901</td>\n",
       "      <td>0.884589</td>\n",
       "      <td>0.839638</td>\n",
       "      <td>0.861341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.483100</td>\n",
       "      <td>2.632432</td>\n",
       "      <td>0.184957</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.141834</td>\n",
       "      <td>0.143120</td>\n",
       "      <td>0.882279</td>\n",
       "      <td>0.838402</td>\n",
       "      <td>0.859597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.380400</td>\n",
       "      <td>2.612310</td>\n",
       "      <td>0.193357</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>0.148707</td>\n",
       "      <td>0.149529</td>\n",
       "      <td>0.888338</td>\n",
       "      <td>0.839547</td>\n",
       "      <td>0.863084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.310500</td>\n",
       "      <td>2.615707</td>\n",
       "      <td>0.197062</td>\n",
       "      <td>0.049129</td>\n",
       "      <td>0.150948</td>\n",
       "      <td>0.152199</td>\n",
       "      <td>0.890291</td>\n",
       "      <td>0.840809</td>\n",
       "      <td>0.864664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.250800</td>\n",
       "      <td>2.605395</td>\n",
       "      <td>0.195306</td>\n",
       "      <td>0.047542</td>\n",
       "      <td>0.148850</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.886120</td>\n",
       "      <td>0.839175</td>\n",
       "      <td>0.861823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.192800</td>\n",
       "      <td>2.618670</td>\n",
       "      <td>0.191812</td>\n",
       "      <td>0.048008</td>\n",
       "      <td>0.147364</td>\n",
       "      <td>0.148298</td>\n",
       "      <td>0.887919</td>\n",
       "      <td>0.839918</td>\n",
       "      <td>0.863068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.127800</td>\n",
       "      <td>2.608866</td>\n",
       "      <td>0.181938</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.141175</td>\n",
       "      <td>0.142304</td>\n",
       "      <td>0.882740</td>\n",
       "      <td>0.838742</td>\n",
       "      <td>0.859982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.073400</td>\n",
       "      <td>2.621601</td>\n",
       "      <td>0.195721</td>\n",
       "      <td>0.049419</td>\n",
       "      <td>0.150306</td>\n",
       "      <td>0.151601</td>\n",
       "      <td>0.887721</td>\n",
       "      <td>0.840070</td>\n",
       "      <td>0.863070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.055900</td>\n",
       "      <td>2.612639</td>\n",
       "      <td>0.190902</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.145902</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.883878</td>\n",
       "      <td>0.838082</td>\n",
       "      <td>0.860181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.979200</td>\n",
       "      <td>2.638881</td>\n",
       "      <td>0.199284</td>\n",
       "      <td>0.050468</td>\n",
       "      <td>0.153486</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>0.891061</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.865174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.972000</td>\n",
       "      <td>2.634185</td>\n",
       "      <td>0.188544</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.144935</td>\n",
       "      <td>0.145526</td>\n",
       "      <td>0.884796</td>\n",
       "      <td>0.838855</td>\n",
       "      <td>0.861014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.923300</td>\n",
       "      <td>2.647159</td>\n",
       "      <td>0.189389</td>\n",
       "      <td>0.045756</td>\n",
       "      <td>0.146533</td>\n",
       "      <td>0.147136</td>\n",
       "      <td>0.886851</td>\n",
       "      <td>0.839961</td>\n",
       "      <td>0.862576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.919300</td>\n",
       "      <td>2.640389</td>\n",
       "      <td>0.189857</td>\n",
       "      <td>0.048095</td>\n",
       "      <td>0.147573</td>\n",
       "      <td>0.148254</td>\n",
       "      <td>0.886831</td>\n",
       "      <td>0.839760</td>\n",
       "      <td>0.862465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.859200</td>\n",
       "      <td>2.653131</td>\n",
       "      <td>0.187313</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.145240</td>\n",
       "      <td>0.146006</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>0.840002</td>\n",
       "      <td>0.862927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.871400</td>\n",
       "      <td>2.661987</td>\n",
       "      <td>0.188330</td>\n",
       "      <td>0.045324</td>\n",
       "      <td>0.146079</td>\n",
       "      <td>0.146882</td>\n",
       "      <td>0.885817</td>\n",
       "      <td>0.839587</td>\n",
       "      <td>0.861888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.850200</td>\n",
       "      <td>2.658078</td>\n",
       "      <td>0.185934</td>\n",
       "      <td>0.044637</td>\n",
       "      <td>0.143239</td>\n",
       "      <td>0.144275</td>\n",
       "      <td>0.885848</td>\n",
       "      <td>0.839832</td>\n",
       "      <td>0.862032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 2638 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2638 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1523 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3794 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1966 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3963 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1533 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 946 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1245 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1745 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2065 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3913 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3913 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1955 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3797 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 756 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 756 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2025 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2025 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3603 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3603 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3833 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2826 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2826 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 855 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2251 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2251 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2028 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2028 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3052 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3052 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 503 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 983 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2761 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3262 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3262 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2067 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3051 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3051 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4011 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4011 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 927 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 927 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2899 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2887 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2247 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2247 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1711 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1711 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2328 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2328 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 743 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2343 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2343 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2061 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2061 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3899 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1656 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1957 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2331 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1164 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1164 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2191 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3927 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3927 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3416 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3540 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3778 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2320 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1861 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1861 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1583 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1583 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 490 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 490 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 440 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 440 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1552 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2366 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2366 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3557 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3557 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1556 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1167 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1167 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1078 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1436 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3781 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3781 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1748 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1772 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1772 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3866 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3866 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2274 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1604 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 886 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3536 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3173 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3173 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2959 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1778 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1778 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1938 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2128 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2459 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3639 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1783 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1214 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2055 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2055 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1654 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2077 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2002 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2002 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 464 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 464 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1398 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1398 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3787 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3787 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 984 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1690 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 679 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3952 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2304 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2304 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1066 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1066 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1564 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2432 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3043 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3043 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3455 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3455 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3079 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3079 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3648 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3648 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 697 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 697 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3932 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2171 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1261 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1261 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2609 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2609 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2334 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 721 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 721 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2960 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3209 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3209 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2762 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1077 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2657 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2657 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 483 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 483 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4032 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4032 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1019 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1461 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2652 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1485 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1485 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1981 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1086 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2372 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2372 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3038 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3038 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2020 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3905 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3905 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 749 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1145 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1145 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2858 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3474 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1688 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1688 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2468 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1176 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3175 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3175 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3936 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3406 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3406 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 674 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3513 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2363 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2363 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1391 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3427 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4038 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4038 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1821 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1821 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3163 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3163 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2649 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2649 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3120 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3120 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3892 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3892 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2989 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2989 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2242 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2242 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2956 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2956 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1725 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3145 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3365 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3365 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 201 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1730 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1730 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2112 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3348 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3020 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3020 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1259 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1259 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 398 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3430 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1412 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3739 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3707 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2219 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2642 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2642 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2630 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2630 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2678 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 987 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 987 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3466 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3466 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 892 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 892 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2498 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2498 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2406 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2406 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2904 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2904 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2643 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2643 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3281 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3281 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3155 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3155 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3352 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1591 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1384 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1384 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2914 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2914 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3147 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3001 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2796 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2796 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2489 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2160 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1652 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3112 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3112 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1161 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1161 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2236 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2236 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2656 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3667 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3667 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3460 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2382 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2458 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2458 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3199 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1814 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1498 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 833 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 833 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2525 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2525 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3324 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1217 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1217 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3016 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3016 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 736 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 736 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3298 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3298 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1427 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1427 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1566 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3382 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3382 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1872 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1309 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1571 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2922 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2349 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2349 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3255 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3255 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 389 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 389 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2139 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2139 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1305 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 894 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3444 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3456 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 642 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 642 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3830 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3830 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3095 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 455 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 455 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2271 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2271 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 843 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 843 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1927 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1927 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1448 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1073 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3594 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1254 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1900 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1455 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3682 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1743 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3002 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2239 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1781 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1781 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2953 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1470 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1470 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1996 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2457 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2457 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 585 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 585 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 802 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 802 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1954 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1954 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3943 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1351 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1351 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2217 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2217 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1349 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4004 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2184 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2184 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2816 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2754 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3230 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2387 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 800 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 800 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3131 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3131 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1125 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1125 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2022 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2022 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 427 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2655 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2318 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2318 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3539 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3539 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 746 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1562 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3588 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3588 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3609 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2958 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3123 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3464 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2663 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1703 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1149 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1149 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2780 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2780 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1962 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1962 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1675 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3000 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3000 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1185 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 968 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1286 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3408 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2032 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2032 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 770 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3265 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3265 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 470 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 470 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2354 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2354 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1452 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1452 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3751 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1607 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1607 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1907 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4019 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4019 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1987 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3926 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3926 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3344 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3344 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3681 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3681 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1672 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3241 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3241 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1830 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1830 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3164 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1074 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1074 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3134 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3134 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1609 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1626 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1626 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3504 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3504 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1754 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3400 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3400 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1007 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2806 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2806 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1612 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3243 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3243 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3438 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2880 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2880 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1200 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3820 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3820 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2275 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 359 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1338 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1338 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 999 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 999 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3789 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2839 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2839 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3738 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3738 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1172 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1812 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1812 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1784 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2926 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2926 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2918 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2918 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3760 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2570 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2570 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2524 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2524 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3235 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2278 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2278 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2238 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2011 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2011 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 462 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 462 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3501 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3506 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3506 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2856 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2831 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2831 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 929 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 929 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3146 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2096 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2096 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3202 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3202 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2853 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2853 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2463 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2463 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2341 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2341 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1280 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1704 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2515 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2515 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2364 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2364 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1677 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1677 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2152 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2757 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2757 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1699 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2297 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2297 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2360 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2360 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 424 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 424 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2159 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2159 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1799 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1799 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2012 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2423 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2423 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1015 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1015 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1943 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3423 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3423 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1729 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3297 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1761 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2088 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1558 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2262 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2644 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2689 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2384 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2866 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2866 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1473 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3333 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2838 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2838 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2321 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2321 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3634 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3634 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3992 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3992 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3236 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3236 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2193 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2049 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2049 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2396 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1468 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1468 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1550 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1550 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3872 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3872 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 558 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 558 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1404 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 804 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1424 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1424 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2789 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2789 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3238 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1240 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1240 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4074 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 902 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 902 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2378 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2378 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2084 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2084 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 923 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 923 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1141 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3339 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 867 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1984 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1984 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1875 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1875 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1290 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3860 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 422 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2169 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2169 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1274 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1274 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 962 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1695 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3360 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1827 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3108 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3108 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3367 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 794 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 794 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2395 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2395 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2462 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2462 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3526 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3271 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3271 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3573 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3573 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3323 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3323 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3880 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2001 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2841 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2841 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 930 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1664 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1664 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3097 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1048 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2332 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1674 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1674 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1548 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1638 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 885 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1441 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2936 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1173 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2080 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2080 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3602 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1135 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1135 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1545 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1545 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 864 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 864 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2605 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1587 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1587 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2747 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1097 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1350 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1350 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 906 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2197 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2197 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4030 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4030 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1848 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1848 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 913 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2900 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3026 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3620 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3620 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3788 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1310 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3358 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3570 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2725 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2693 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3812 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3121 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3189 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2137 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3709 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2892 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2548 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 914 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1426 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3425 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3214 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1668 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1986 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3578 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3068 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3757 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2411 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3768 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2256 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2694 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2888 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3710 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1294 to 2048 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122db0b28080405e9e7a59fb676e5125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f38aad4e44c7d8894c9585a839a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3256c14f43450fbe57a9f616c4a431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3f107ddbe54265b87a03fedb8a4b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e93608b96344048609a02c43bb6cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e044648d8b4049e5891270a857a5dab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Input ids are automatically padded from 1224 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 2878 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2878 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3654 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3654 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 991 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1114 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3472 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3472 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3922 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3922 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1142 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1142 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1993 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1993 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2071 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2071 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1606 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1606 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1370 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1658 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2737 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1329 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1329 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2062 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3378 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1277 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 851 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 745 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 745 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1563 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1563 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2264 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1117 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 750 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 750 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1064 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1190 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1190 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2676 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2864 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2449 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2803 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1870 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2522 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3804 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3804 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1531 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1531 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1418 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2310 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1701 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1701 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3046 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3467 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3467 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2720 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2720 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3745 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3514 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3514 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2975 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2975 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2478 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2478 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1546 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1222 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3945 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3945 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2369 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2117 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2117 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2756 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 405 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2148 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2148 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1990 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1990 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1775 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2326 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3591 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3591 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1526 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2683 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2683 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2723 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1741 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 429 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 429 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1306 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2373 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2373 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2785 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3660 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3660 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1599 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2194 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3305 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2943 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2943 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3968 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3968 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2208 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 436 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 436 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2964 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1372 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 907 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1903 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1903 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1410 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1410 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2928 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2928 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1432 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1432 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1588 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2546 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1479 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1479 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1828 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1828 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 603 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3479 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1829 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3884 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 474 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2042 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2042 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1367 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1367 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2286 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3524 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1670 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1670 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1868 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2269 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2269 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2592 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2592 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3763 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1227 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2963 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 897 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3442 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1510 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 792 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 792 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3994 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3994 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2771 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2490 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3487 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1083 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1083 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 925 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2124 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3569 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3082 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2820 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2820 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3368 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1030 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1866 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1866 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1765 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1801 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1387 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2036 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2036 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2543 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2543 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1489 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1489 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2009 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1534 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2235 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1516 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1516 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1917 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2228 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2228 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3208 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3208 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1976 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2401 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2401 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3341 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3341 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1867 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1867 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1570 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1004 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1004 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2669 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1089 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1089 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1557 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1557 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1921 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 954 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 797 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 797 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2487 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2487 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1770 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 844 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1021 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1021 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2742 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2742 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1967 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3330 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3330 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1595 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1595 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1786 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 382 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1221 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1221 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3251 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3251 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1691 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1100 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1100 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 555 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1547 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1547 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2879 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2879 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1191 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3115 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3115 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 523 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 523 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3920 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3920 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3017 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2556 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2556 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1629 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1629 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2322 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2140 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2140 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3947 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 860 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1487 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1487 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3554 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3554 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2759 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3488 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3538 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 454 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2357 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2357 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1660 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1184 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3074 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3074 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1794 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 543 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 543 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2582 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2582 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1726 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3629 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3629 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1891 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3550 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3550 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2528 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1611 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1611 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2133 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1099 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1099 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 872 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 515 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1811 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3900 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3900 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3708 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1213 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1234 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3494 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3494 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2659 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2659 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3212 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3212 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2648 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2648 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2211 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2211 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2394 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2394 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2571 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1902 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1902 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1876 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3750 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3750 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1705 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1952 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1952 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3564 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1435 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1435 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3851 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3851 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3390 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3390 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2379 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2379 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2218 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2218 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1513 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3727 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3727 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2482 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2299 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1985 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2279 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1842 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1842 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3717 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3717 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 453 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1666 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1666 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3933 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3933 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1843 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 702 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3475 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3475 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3652 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3652 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3273 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2255 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2270 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 431 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1439 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2807 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2290 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2290 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1953 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1098 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1098 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4080 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2428 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2428 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1795 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1795 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3954 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3726 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3726 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3338 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3338 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1296 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3585 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3585 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3551 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3551 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 873 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3575 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3575 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3953 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3953 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 944 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4077 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2915 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1700 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1250 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 218 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1882 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1882 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3824 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3824 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3301 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3301 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2603 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2603 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3078 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3895 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3895 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1146 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1146 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1582 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1582 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 394 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1908 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1908 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1246 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2533 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 561 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 561 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1378 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3931 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 905 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 905 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4083 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2298 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2308 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1110 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1110 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3852 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3852 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3930 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 738 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 738 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2601 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 973 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2241 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3399 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3876 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3182 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1155 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2421 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2034 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2034 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2766 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2766 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2516 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2516 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 590 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 590 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1035 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1035 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1973 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1973 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3267 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2414 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2414 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1744 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1744 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3177 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3177 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1156 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1156 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1919 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1919 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3482 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3482 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1878 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1878 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3380 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2499 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2499 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2173 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3021 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2801 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2801 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3680 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2983 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2983 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2991 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3528 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1103 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1103 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2660 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2660 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1988 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2254 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2254 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2285 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2285 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3823 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3823 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 918 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2145 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2145 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 420 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 420 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2970 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2970 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1454 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1454 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1348 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1348 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2823 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2823 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 718 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 888 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2046 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2999 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1899 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1899 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1816 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3841 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3837 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 569 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1046 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1046 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1009 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1009 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1326 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1326 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1440 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1440 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3698 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 846 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 846 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1356 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1356 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4009 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4009 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1865 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3955 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3955 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3810 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1627 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1017 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1017 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3865 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1229 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2517 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1525 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3610 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1858 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3773 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3773 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4088 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1288 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1802 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2903 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1851 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2950 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2950 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 835 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 835 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2039 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2039 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2935 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2935 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3696 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3227 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1511 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1308 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1308 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 451 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 451 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3160 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3160 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3988 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1991 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3697 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1553 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 713 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3491 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3491 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 489 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3976 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2419 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2419 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2471 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3957 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3957 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 638 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 3135 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3135 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3181 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2773 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1187 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1187 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1810 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1810 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1860 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1199 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1393 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 938 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 938 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1999 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1999 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2445 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1235 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1235 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3197 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3197 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1787 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1787 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2604 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3574 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1124 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 921 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1361 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1361 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1779 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1792 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1792 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1864 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3915 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 964 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 964 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1678 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1678 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 675 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 675 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2268 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 413 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 413 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3571 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3571 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3307 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3307 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2162 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2233 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2233 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1913 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2706 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2706 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 488 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2257 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2257 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2919 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2453 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2453 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1457 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1457 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2901 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 764 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1702 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1702 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2711 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2711 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1615 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1615 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 857 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 857 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1198 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1198 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2210 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 893 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 893 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1540 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2667 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 960 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3901 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3901 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 551 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3259 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 234 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3226 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2779 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2779 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1123 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1123 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2613 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3154 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1720 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1720 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2832 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2832 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3990 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3990 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1047 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2995 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3256 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3256 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2514 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2514 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 811 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3721 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2069 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 875 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3816 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 726 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1059 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1059 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4040 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4040 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1959 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2098 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1603 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1603 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3229 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1380 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2126 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2126 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2198 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2198 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1503 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1767 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2026 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2026 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 996 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 996 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 519 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2053 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2053 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1733 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1273 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2464 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2464 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2699 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2699 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2288 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2288 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3459 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1693 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3463 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2108 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2108 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 898 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 898 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1303 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1303 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2177 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2177 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1769 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3450 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3450 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3240 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2834 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2834 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2994 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3081 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3081 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2057 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2057 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1311 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3206 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2439 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2439 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2567 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2567 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2047 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1300 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1300 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 822 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2245 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2245 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1317 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3328 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3328 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 997 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3691 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3440 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2599 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3799 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1968 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1968 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1401 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1401 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1940 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2221 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1257 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1257 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1425 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1425 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3036 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2637 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3150 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3306 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 934 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 934 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1085 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1196 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1196 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3916 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 346 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3042 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3042 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1079 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2081 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2081 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 354 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1447 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1447 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1270 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3063 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 452 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 452 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1662 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1662 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3073 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3073 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3102 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2939 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3596 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 866 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2093 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2093 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1992 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1992 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2890 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3984 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3984 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1371 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1371 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 899 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 899 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2043 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1346 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1911 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1911 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 435 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2014 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1208 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1742 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1742 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1215 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1215 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1512 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1512 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3441 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3441 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3014 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3014 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1061 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2155 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2155 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3828 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3828 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1541 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1541 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1152 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1152 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 829 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2739 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2805 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1490 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3302 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3302 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1263 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1263 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1475 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2106 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2894 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2894 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2253 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2253 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2846 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2846 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1088 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1791 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1791 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4072 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1052 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1052 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1551 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1551 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 780 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 966 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2721 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2721 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3530 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3530 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3012 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3012 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1115 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1115 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2979 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2979 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1327 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2079 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2079 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2908 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2908 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1707 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1304 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1304 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1689 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1689 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 627 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 627 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2161 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1671 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3192 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2383 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2383 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2984 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2984 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3275 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3275 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3092 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3092 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2610 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1255 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3313 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 767 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 767 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 842 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 945 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 945 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3572 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3572 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1093 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1093 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1983 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4066 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4066 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1063 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1050 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3342 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1014 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1014 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1972 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1972 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1663 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1655 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1655 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3480 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3480 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3290 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3290 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4078 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1998 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1998 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2633 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2633 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1774 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1774 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 504 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 504 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1714 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1714 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1394 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2815 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2664 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2664 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2141 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 878 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2620 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 995 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 891 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 891 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1788 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2465 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2465 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1970 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1939 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1939 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1344 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1344 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2632 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2632 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1495 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 546 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 546 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 491 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1463 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1463 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3401 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3401 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3244 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3244 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1095 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1759 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1051 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3269 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3269 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2246 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 587 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 587 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1183 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2847 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2847 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1253 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1253 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3635 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2784 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2784 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2127 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2127 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2113 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2113 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3310 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3310 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2231 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2187 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2063 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2063 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1621 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1621 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 963 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 963 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3218 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 943 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 943 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3172 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2375 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2375 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3815 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3815 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1709 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1709 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1945 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2982 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1075 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2734 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3923 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3923 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1708 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1708 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3515 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1597 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1887 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3645 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3645 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 486 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 486 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3643 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3643 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3443 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3443 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2309 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 698 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 698 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1752 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1231 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2494 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 795 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 795 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1287 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2510 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2510 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1453 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 446 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1643 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1643 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 471 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 471 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 297 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1298 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1298 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2473 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1467 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1467 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1260 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2596 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2596 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2735 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2735 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1623 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1283 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 521 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 521 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 657 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 657 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3332 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1636 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2830 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2830 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3676 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4024 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4024 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2417 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2705 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2705 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2639 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2639 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 613 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 772 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1676 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2869 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 498 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 967 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1071 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1071 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1101 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1101 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1782 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1782 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1000 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2653 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 731 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 493 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 493 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 591 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 399 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1665 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1684 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1684 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1029 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1029 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 853 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 853 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3105 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1739 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 367 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 367 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1206 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1206 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2102 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1108 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1108 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1165 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 653 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 508 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 508 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 517 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2368 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2368 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1877 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 559 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1316 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 513 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2230 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 1789 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1789 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1760 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1544 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2507 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2507 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1721 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3925 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3925 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1857 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1537 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2188 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1853 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 775 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 775 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1136 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2064 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2064 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2044 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1055 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1605 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1605 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1521 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1521 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1039 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1039 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 977 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2186 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2186 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1010 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1010 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2997 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2997 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1210 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1210 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1417 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1417 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 928 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 928 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2130 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1905 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1905 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2229 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2229 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 917 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 917 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 776 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 650 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2100 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1519 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1519 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2932 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2932 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1722 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1722 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1501 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1653 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 614 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 614 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1478 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 635 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1219 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1219 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1354 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1354 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 423 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 889 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 760 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 760 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 306 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1399 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1804 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1804 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2066 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2314 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2314 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 862 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 862 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2121 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2736 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2736 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1067 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2385 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2385 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1223 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1223 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1673 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1673 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 437 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1438 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1438 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 978 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1151 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1151 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1174 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1174 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 703 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3350 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 355 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 355 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1400 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1400 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 289 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3015 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2082 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2082 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 362 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2150 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2150 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1102 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1205 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1926 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1926 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1826 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1826 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 994 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 994 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 778 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 778 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2931 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 601 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3207 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3207 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1170 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2107 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2107 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2316 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1330 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1803 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1803 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1575 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1575 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3096 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 992 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3090 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2351 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 348 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 348 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1385 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2013 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2013 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 335 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 335 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 958 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 958 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 623 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2444 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1345 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 1824 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1824 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1573 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1573 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1179 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1879 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1879 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3690 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 708 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 708 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2881 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2881 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1405 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1405 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 896 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 896 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1209 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1209 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2324 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2324 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2426 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3099 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3099 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1442 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1442 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3144 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1578 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1578 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3300 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3300 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3426 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3426 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1647 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1647 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 729 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 729 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1389 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1389 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3878 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1508 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2250 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 744 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 744 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3802 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3802 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1922 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1922 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1798 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1639 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1639 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1650 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 887 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 887 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 351 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 351 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 874 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1239 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 480 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 480 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2532 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1237 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1237 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3388 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3388 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4069 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4069 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 397 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1657 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1657 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1197 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1197 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1747 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 837 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 837 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1914 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1914 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1482 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1482 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1633 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2986 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2986 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 255 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 255 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 275 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 275 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2687 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1484 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1484 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 722 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 199 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 497 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 856 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 856 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1252 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1252 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 415 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2985 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 626 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1355 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 496 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 986 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3130 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 919 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 299 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 563 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1715 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1715 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3257 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 771 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 771 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 478 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3421 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3421 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 869 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 328 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2527 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 547 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 547 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1834 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1834 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1856 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 360 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 360 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 223 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 472 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 949 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1859 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1859 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2392 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1477 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1477 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1295 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1295 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1630 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1694 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1694 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 307 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 307 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 694 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 694 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3138 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 584 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3060 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3060 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2684 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1443 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 605 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 605 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1763 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1763 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1204 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1126 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1126 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 651 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 651 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 643 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1291 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1291 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1620 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2506 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1315 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1315 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1492 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 942 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 942 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1301 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1301 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 583 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 1144 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1449 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1449 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2760 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 990 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1712 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1712 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1012 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1012 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1581 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1211 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2813 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2813 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 714 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 881 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1236 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1236 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1262 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 482 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 482 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 571 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 940 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 940 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2243 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2243 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1118 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 528 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 509 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 509 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1268 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 821 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 821 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 473 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 473 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2138 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3280 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3280 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1839 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 602 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 602 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1382 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2451 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2451 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 839 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1596 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1628 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2252 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2252 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 723 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 381 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 381 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1756 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1756 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1408 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1408 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 664 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 575 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1153 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1153 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 579 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 579 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 554 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 554 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1013 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 386 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 588 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 588 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 631 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3114 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 421 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 879 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 879 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1880 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1880 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1529 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1413 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 369 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 532 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1888 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1888 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 293 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 293 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1884 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1884 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 644 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 644 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 401 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1869 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1869 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 724 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 442 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 442 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 809 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 809 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 577 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2967 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 259 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 514 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 514 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 449 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3080 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3080 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3011 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 527 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1560 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1560 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 406 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 406 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1488 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1488 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1119 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1119 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 492 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1065 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2425 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 680 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 680 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 717 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 717 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1358 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1358 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1266 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1266 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 439 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 507 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 507 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 457 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 814 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 953 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 953 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 861 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1644 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 357 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 357 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2301 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 704 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1930 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1930 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1651 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1651 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2358 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1359 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1359 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 291 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 334 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1631 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 502 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 502 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 910 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 910 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 882 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 882 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1353 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1353 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 284 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1192 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1502 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 288 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 288 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 712 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 1060 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1060 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1057 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1057 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1360 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1360 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1854 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1751 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1751 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 350 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 350 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 525 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 525 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1936 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 728 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 728 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 372 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 372 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2305 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 495 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 196 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 196 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 961 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 961 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 215 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1920 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1920 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1364 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 395 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1396 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1396 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 947 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 748 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 748 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 308 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 308 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 500 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1749 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 247 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 247 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 358 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 358 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 763 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1472 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1472 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 376 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 349 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 349 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 828 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 828 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 231 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1601 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 131 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1106 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1106 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1096 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 434 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 931 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 383 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 318 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 52 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 2520 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2520 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 222 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 838 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 838 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2017 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2017 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1469 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1469 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2154 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2154 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2412 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1147 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1147 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 522 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 735 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 735 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 922 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 933 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 684 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 684 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1669 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 827 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2294 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 568 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 444 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 438 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 1352 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1352 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1188 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1188 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2220 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2220 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 484 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 484 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 326 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 326 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 340 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 340 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 586 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 586 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 375 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 937 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 937 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 466 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1182 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 607 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1375 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 834 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 425 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 425 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 529 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 529 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 408 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1202 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1105 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1105 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 501 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1069 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 972 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 972 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 840 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 840 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1241 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1241 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 648 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 241 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1005 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1005 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 510 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 412 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 412 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 404 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 404 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 430 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 533 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 533 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 479 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 823 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 463 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 463 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1177 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1177 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1072 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 665 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2607 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 511 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 511 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 294 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 688 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 688 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 47 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 810 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1554 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1554 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 791 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 791 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 782 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 789 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 390 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 477 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 975 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 975 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 645 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 645 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 580 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 580 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1390 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1390 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 552 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 403 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 403 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 272 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 272 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 411 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 411 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 400 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 538 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 989 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 989 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 341 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 336 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 336 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 465 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 676 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 339 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 339 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 950 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 950 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 610 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 693 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 693 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "There were missing keys in the checkpoint model loaded: ['led.encoder.embed_tokens.weight', 'led.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18760, training_loss=2.180251496077092, metrics={'train_runtime': 37090.9901, 'train_samples_per_second': 1.012, 'train_steps_per_second': 0.506, 'total_flos': 7.842311433274982e+16, 'train_loss': 2.180251496077092, 'epoch': 10.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84401a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:00:27.416889Z",
     "iopub.status.busy": "2025-05-18T08:00:27.416595Z",
     "iopub.status.idle": "2025-05-18T08:00:28.807769Z",
     "shell.execute_reply": "2025-05-18T08:00:28.806956Z"
    },
    "papermill": {
     "duration": 1.510848,
     "end_time": "2025-05-18T08:00:28.809346",
     "exception": false,
     "start_time": "2025-05-18T08:00:27.298498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"my_final_centrum\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6844177,
     "sourceId": 11015649,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37154.908621,
   "end_time": "2025-05-18T08:00:32.431955",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-17T21:41:17.523334",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c81c3546164618a2752fa3dec3662f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2aca0cf074924176aa06665edfd86751",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d515d10507834ee9a9ca8888ba066312",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá100%"
      }
     },
     "039d516ee0e64356bbb2efb79bb79f17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47770b30f4094b9abc085f51a6662163",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c049067c71624514ad1bed0d497b08f4",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:‚Äá100%"
      }
     },
     "046e382efe294995a35d1de25e04c344": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f77fc1b4d2b469e9eacc43dc62405f2",
       "max": 1421700479.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_babfd8a5f4774a86852a7268732e9b28",
       "tabbable": null,
       "tooltip": null,
       "value": 1421700479.0
      }
     },
     "05c5e043495c499389673164be18bffc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a7e06b5b1cd14d8887c121b9d613b410",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c6ad4b1f0f2b40419cb38f041304983f",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading‚Äábuilder‚Äáscript:‚Äá100%"
      }
     },
     "06f4f5e7afa04a4f9fe14b6f5618c14e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bab9bcdc098402c9fa74cb8cba5efe6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cacf5d0ae5b84508a746087715137866",
       "max": 168.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bc8a79229e28438682536792b1334a1a",
       "tabbable": null,
       "tooltip": null,
       "value": 168.0
      }
     },
     "0d5e0723c57e4f999d217e60fd9de9dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0f4405d33bd04018940f2f801315bff0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_546d853e47aa401f9526fcd2c82bc289",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3e8c82aec1b7473b968ccc0c4010c10b",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json:‚Äá100%"
      }
     },
     "11478a30df5040008d98496a701bab82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "122db0b28080405e9e7a59fb676e5125": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_699c6ccfab1d499c8463b8af75771dea",
        "IPY_MODEL_ca36c635987d43efb6fbf9e47a4e8eef",
        "IPY_MODEL_decf975ba3a845d2950c3ce6490d8599"
       ],
       "layout": "IPY_MODEL_2d124be287d44f6581a2c46c164c08b1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "125b620df1504a7483a5af27d4fdf09c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ea6852d9f6254550973b7fea85270364",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_24b04bbcb98549eb9ce7edd34b3e09e0",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá899k/899k‚Äá[00:00&lt;00:00,‚Äá13.9MB/s]"
      }
     },
     "133cef4e0c9b4b568b7d91a3b6d3ca05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14f0d3193f69448c9cdac530524c8f66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_99fbc5ef43f8452ca85556ce3a5262a4",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ac74b247b2534f6e8aa6e1ff07147ad1",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:‚Äá100%"
      }
     },
     "15765da5751d4e9eb66ed63ec49edbe1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "186620e585094b4399dc589490893128": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a0d6db19aab48aea89a09fafbd383d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b86d9c1abbd64c79b51d5561144b05b0",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9f4864fdf19b459181feb1fa52c7df9d",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:‚Äá100%"
      }
     },
     "1cf817da8d5449879660f05815cd8d5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_186620e585094b4399dc589490893128",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_862c7ccac05040fea18297d2e800edaa",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá899k/899k‚Äá[00:00&lt;00:00,‚Äá17.4MB/s]"
      }
     },
     "1f77fc1b4d2b469e9eacc43dc62405f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "200fd92ca53048d6a53d9240f25460e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "24762cb6c003407596da49d271d057bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "24b04bbcb98549eb9ce7edd34b3e09e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "262dd4afb4764a8eab47874fda6427db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f4405d33bd04018940f2f801315bff0",
        "IPY_MODEL_0bab9bcdc098402c9fa74cb8cba5efe6",
        "IPY_MODEL_aa35a96cb51f4fad9aa9f554e17f80e7"
       ],
       "layout": "IPY_MODEL_b1b0cfee72dc43589d2ed2175bba781c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2774153878f84eacac365511b6561874": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2827403f24a947cbbda12f93b046c0e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "29ff66592d4f434d9425c209e45642fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a4dab6f6b43451f85a8ee0c449c965c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6441b38750b844149562de1df9b94fe2",
       "max": 1355863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a0a7c762c14847fc872ac4ff062a15fa",
       "tabbable": null,
       "tooltip": null,
       "value": 1355863.0
      }
     },
     "2aca0cf074924176aa06665edfd86751": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c3f107ddbe54265b87a03fedb8a4b0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fd063f0bc3d441a8bca0497f408ce64e",
        "IPY_MODEL_3f66dc2bda2d4b1b97285e78263fcd26",
        "IPY_MODEL_ad33c2bfa7d346969efd0ebbb1b12066"
       ],
       "layout": "IPY_MODEL_76df405230c64a1b8ec277bf10a9fd2e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2d124be287d44f6581a2c46c164c08b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2df7dadb06aa4cc7b041ba54f6c13834": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f713da372d8416a8d28d8679243adb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_94cc6441e44448e3a14e7d1d445d8b1a",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_24762cb6c003407596da49d271d057bb",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá27.0/27.0‚Äá[00:00&lt;00:00,‚Äá2.61kB/s]"
      }
     },
     "2f723dfa05544fcaa807edecc621158d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "32b01027ddfa4105b2b0c71940c5f4e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "32fdfa7d90fc4b85839570763c04be6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "382b93fc11394883a3d31457ce683504": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "39c627032ba849f1bacc694fd34406b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c024de7f097431b985b5746895c605b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c80b869dff143f3ab0d43dc5d15ef69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_504ddb236591484cbcc1bac0e0b38f08",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4187fc6034ec46b6b4edd972a3ac6e0b",
       "tabbable": null,
       "tooltip": null,
       "value": "Downloading‚Äábuilder‚Äáscript:‚Äá100%"
      }
     },
     "3e4f5a53a7f249b0b952721b52d7cc2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f90cb09c7ada486f875a4abd1afbb0fd",
        "IPY_MODEL_b672920821bc49b4bf56e3c3328c49db",
        "IPY_MODEL_4260e12eb03c46fca1ca9b6d722b2fec"
       ],
       "layout": "IPY_MODEL_936113f006e5407fa6b70f9d6e022b33",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3e8c82aec1b7473b968ccc0c4010c10b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3f66dc2bda2d4b1b97285e78263fcd26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8594537dfeb34c1a94e8da0cbe0a57ca",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7c785312cae548919c7903724795d1ff",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "40cf8349495c453a8b69966ba0c5b0e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4187fc6034ec46b6b4edd972a3ac6e0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4260e12eb03c46fca1ca9b6d722b2fec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8726f41d60d9440a9e009ee148df807d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ecd1f6d75cb54f59ab758c3ef75c567a",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá456k/456k‚Äá[00:00&lt;00:00,‚Äá26.6MB/s]"
      }
     },
     "431c8b55788e4bdb998f0c81dd452b99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15765da5751d4e9eb66ed63ec49edbe1",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_40cf8349495c453a8b69966ba0c5b0e2",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá7.95k/7.95k‚Äá[00:00&lt;00:00,‚Äá691kB/s]"
      }
     },
     "438e4e4707e0437caa750e01b4bb0d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_beb659fde3ae4283970895380605a918",
       "max": 482.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_afd4159af9bc434dbff167dd93547309",
       "tabbable": null,
       "tooltip": null,
       "value": 482.0
      }
     },
     "45183b8174854ea381ddbd2783bed6d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "471fe13218a940dbb98a3735e94468a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab09eeb4652d4ac2b4e88347b5969354",
       "max": 898822.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aaa64369ce6e41cf8143edac99ef947c",
       "tabbable": null,
       "tooltip": null,
       "value": 898822.0
      }
     },
     "4731f01ce05b4c9a83dacc04b1620245": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a9709b485ebf4661a731204281bdbb9e",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_678cc7729e9b4ff6ac16868eb29f8532",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.36M/1.36M‚Äá[00:00&lt;00:00,‚Äá43.3MB/s]"
      }
     },
     "47770b30f4094b9abc085f51a6662163": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48d854cffcb64893945b0ba54b725050": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64a53f20c02a4caf829d05e5a2218fb2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_fab94765139b44a79005106124a82611",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá648M/648M‚Äá[00:02&lt;00:00,‚Äá261MB/s]"
      }
     },
     "4dc346dae8ca479d83c4c79c1b5c162c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ea091885392437ab03b63d376590fd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "504ddb236591484cbcc1bac0e0b38f08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51048d626d75449680f4b5bc68c02a57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "527f38aad4e44c7d8894c9585a839a0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00c81c3546164618a2752fa3dec3662f",
        "IPY_MODEL_438e4e4707e0437caa750e01b4bb0d1e",
        "IPY_MODEL_5be4b81d57db497784116f775e7a381e"
       ],
       "layout": "IPY_MODEL_f62b2cbf480a42cfa3685375e2e0fe9f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "546d853e47aa401f9526fcd2c82bc289": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54f8cdb1a9a445aa8a82bce580ee8d0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a59914e64b6473fa72f434709d61302": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5add1a2b4f5241f889df369d35541890": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b8f46e99f964b58831f6457277d1a9b",
       "max": 1092.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2827403f24a947cbbda12f93b046c0e2",
       "tabbable": null,
       "tooltip": null,
       "value": 1092.0
      }
     },
     "5bc4dbee47b846e2a716afe19eae2b89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5be4b81d57db497784116f775e7a381e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aeb3f790c22f4f8685f3709a4f6fa88e",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f8fc74ef127944a3ac09a4ff72eea19a",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá482/482‚Äá[00:00&lt;00:00,‚Äá52.4kB/s]"
      }
     },
     "5e7799f9f6d447e28a3206cbb83f1f06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5fc62f2edc93491c85de9a9a24e61a21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6441b38750b844149562de1df9b94fe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64a53f20c02a4caf829d05e5a2218fb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "678cc7729e9b4ff6ac16868eb29f8532": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6805335b95ef4270bd03530c4259564f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39c627032ba849f1bacc694fd34406b5",
       "max": 7950.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e57e455270ea4775ad097c6f457aef48",
       "tabbable": null,
       "tooltip": null,
       "value": 7950.0
      }
     },
     "6867a6d72dd442e8bb76daf8950756c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "699c6ccfab1d499c8463b8af75771dea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fc6b7ec93929429eb3cc8d8a95223920",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_32b01027ddfa4105b2b0c71940c5f4e2",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:‚Äá100%"
      }
     },
     "6bfcf6d1a06149d8abc77a7feb5fef5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cf53cc423a3465089de20006956d898": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e03882ef4614aceafd78c15b515f5d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78c41721fe204651ac653f594e128ff9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_868945785699414e820bbfe194f01845",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.42G/1.42G‚Äá[00:05&lt;00:00,‚Äá261MB/s]"
      }
     },
     "6e3256c14f43450fbe57a9f616c4a431": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8e4e8fba8834338a940ae5c2c131986",
        "IPY_MODEL_cc766eebd87e4f61b3a17ea0ab35c7fa",
        "IPY_MODEL_1cf817da8d5449879660f05815cd8d5d"
       ],
       "layout": "IPY_MODEL_3c024de7f097431b985b5746895c605b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "73e93608b96344048609a02c43bb6cea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_14f0d3193f69448c9cdac530524c8f66",
        "IPY_MODEL_2a4dab6f6b43451f85a8ee0c449c965c",
        "IPY_MODEL_4731f01ce05b4c9a83dacc04b1620245"
       ],
       "layout": "IPY_MODEL_8110bee423cc4addbf8c512293f1be4d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "76df405230c64a1b8ec277bf10a9fd2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76f67c8178c344f184c2ec7b08f5fc3d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78c41721fe204651ac653f594e128ff9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79e23166f18a40b9ba016c86e6409892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eaf7bde72e224e3f84973815a7ffd9f3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a4195244577349c79983c8b7514abbee",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin:‚Äá100%"
      }
     },
     "7c785312cae548919c7903724795d1ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d09ce8b922846799fa739ee84a5a65d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7e46c0aa748546429841ebfe85388605": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8110bee423cc4addbf8c512293f1be4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83b5e460b11f447f836dc9f7c8dacefe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8594537dfeb34c1a94e8da0cbe0a57ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "862c7ccac05040fea18297d2e800edaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "86546057376b47e0b6ced5da67e7b13f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "868945785699414e820bbfe194f01845": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8726f41d60d9440a9e009ee148df807d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "872e1f22edc4474a85541f6239f30bf2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_54f8cdb1a9a445aa8a82bce580ee8d0b",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_83b5e460b11f447f836dc9f7c8dacefe",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:‚Äá100%"
      }
     },
     "8797bd7380a249ccaf8ea020b6f62e4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dea3955dbc7545e683a5e66262a48f81",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_b68d778a16654541a69cb52559a75870",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.09k/1.09k‚Äá[00:00&lt;00:00,‚Äá108kB/s]"
      }
     },
     "87bf1aaf56754c7dba4f47f7677fa063": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "91545cfed0184743b67deb0facaab286": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_32fdfa7d90fc4b85839570763c04be6e",
       "max": 6270.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f6103646931b4255888d0e285fdd18be",
       "tabbable": null,
       "tooltip": null,
       "value": 6270.0
      }
     },
     "936113f006e5407fa6b70f9d6e022b33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94cc6441e44448e3a14e7d1d445d8b1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96319ae2adb6467c91156a18f1c38d42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9836e2edd7b647d6b2e8c96d4b1f22da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_872e1f22edc4474a85541f6239f30bf2",
        "IPY_MODEL_ff21f4a56d274e598507ba25af0d1719",
        "IPY_MODEL_ca9e2c88ac4b46aa9787e10e8d1c76c9"
       ],
       "layout": "IPY_MODEL_5a59914e64b6473fa72f434709d61302",
       "tabbable": null,
       "tooltip": null
      }
     },
     "990ac329136e4787a50bac63f2bdb8dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "99fbc5ef43f8452ca85556ce3a5262a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b8f46e99f964b58831f6457277d1a9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e4920e45aa44dbc9bbaf611244c05f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f4864fdf19b459181feb1fa52c7df9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a0a7c762c14847fc872ac4ff062a15fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a24df3559f934eca92edff2b8bd5a265": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_51048d626d75449680f4b5bc68c02a57",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_b96c1ad4b7d641319c3c7dfcc81645da",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá6.27k/6.27k‚Äá[00:00&lt;00:00,‚Äá603kB/s]"
      }
     },
     "a4195244577349c79983c8b7514abbee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a42ee61ccdab41dd9ba7c8cef97952bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7e06b5b1cd14d8887c121b9d613b410": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a962bbb31b624ad59a4887fbe0f14f0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_79e23166f18a40b9ba016c86e6409892",
        "IPY_MODEL_f01f5806e00542339f5d8f3910bf85bf",
        "IPY_MODEL_48d854cffcb64893945b0ba54b725050"
       ],
       "layout": "IPY_MODEL_6867a6d72dd442e8bb76daf8950756c4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a9709b485ebf4661a731204281bdbb9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa35a96cb51f4fad9aa9f554e17f80e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f6d4f2f73dee4beeb6bdd17aca293e13",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f92bd864fe5f4427b9b740e4607d224c",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá168/168‚Äá[00:00&lt;00:00,‚Äá15.7kB/s]"
      }
     },
     "aaa64369ce6e41cf8143edac99ef947c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab09eeb4652d4ac2b4e88347b5969354": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abea01b54a814e03ba47caec37d1789d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c2d8a8fbae064aa9a4aa18cbf0193f62",
        "IPY_MODEL_5add1a2b4f5241f889df369d35541890",
        "IPY_MODEL_8797bd7380a249ccaf8ea020b6f62e4b"
       ],
       "layout": "IPY_MODEL_2df7dadb06aa4cc7b041ba54f6c13834",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ac74b247b2534f6e8aa6e1ff07147ad1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ad33c2bfa7d346969efd0ebbb1b12066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_06f4f5e7afa04a4f9fe14b6f5618c14e",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_990ac329136e4787a50bac63f2bdb8dc",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá456k/456k‚Äá[00:00&lt;00:00,‚Äá21.5MB/s]"
      }
     },
     "aeb3f790c22f4f8685f3709a4f6fa88e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afd4159af9bc434dbff167dd93547309": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b1b0cfee72dc43589d2ed2175bba781c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5d168b27160461f9976d1e5fb424210": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b672920821bc49b4bf56e3c3328c49db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e7799f9f6d447e28a3206cbb83f1f06",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dee91443855446d8a647f24fffa6d638",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "b68d778a16654541a69cb52559a75870": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b86d9c1abbd64c79b51d5561144b05b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b96c1ad4b7d641319c3c7dfcc81645da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "babfd8a5f4774a86852a7268732e9b28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bc74d71124224362be2c6966bf0e289f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05c5e043495c499389673164be18bffc",
        "IPY_MODEL_91545cfed0184743b67deb0facaab286",
        "IPY_MODEL_a24df3559f934eca92edff2b8bd5a265"
       ],
       "layout": "IPY_MODEL_96319ae2adb6467c91156a18f1c38d42",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bc8a79229e28438682536792b1334a1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bea1a7fd33394e3bb48d1225151630ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_86546057376b47e0b6ced5da67e7b13f",
       "max": 27.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d5e0723c57e4f999d217e60fd9de9dd",
       "tabbable": null,
       "tooltip": null,
       "value": 27.0
      }
     },
     "beb659fde3ae4283970895380605a918": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c049067c71624514ad1bed0d497b08f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c1f8ca0cd70f496d82aaec05c307d950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_039d516ee0e64356bbb2efb79bb79f17",
        "IPY_MODEL_471fe13218a940dbb98a3735e94468a2",
        "IPY_MODEL_125b620df1504a7483a5af27d4fdf09c"
       ],
       "layout": "IPY_MODEL_4dc346dae8ca479d83c4c79c1b5c162c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c2d8a8fbae064aa9a4aa18cbf0193f62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_29ff66592d4f434d9425c209e45642fc",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2f723dfa05544fcaa807edecc621158d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá100%"
      }
     },
     "c6ad4b1f0f2b40419cb38f041304983f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca36c635987d43efb6fbf9e47a4e8eef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e4920e45aa44dbc9bbaf611244c05f0",
       "max": 25.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2774153878f84eacac365511b6561874",
       "tabbable": null,
       "tooltip": null,
       "value": 25.0
      }
     },
     "ca9e2c88ac4b46aa9787e10e8d1c76c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f10cef5ba69e43ebb220fa310fd2f14b",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_133cef4e0c9b4b568b7d91a3b6d3ca05",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá772/772‚Äá[00:00&lt;00:00,‚Äá83.6kB/s]"
      }
     },
     "cacf5d0ae5b84508a746087715137866": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc766eebd87e4f61b3a17ea0ab35c7fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76f67c8178c344f184c2ec7b08f5fc3d",
       "max": 898823.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_200fd92ca53048d6a53d9240f25460e5",
       "tabbable": null,
       "tooltip": null,
       "value": 898823.0
      }
     },
     "cf6517c3885a4f51bc1611b5d6fe7438": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d515d10507834ee9a9ca8888ba066312": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8d8742d9eec4635b5d386e5d00e7c50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dea3955dbc7545e683a5e66262a48f81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "decf975ba3a845d2950c3ce6490d8599": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f98974263b804838aeb5c7d06e4de313",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_87bf1aaf56754c7dba4f47f7677fa063",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá25.0/25.0‚Äá[00:00&lt;00:00,‚Äá2.54kB/s]"
      }
     },
     "dee91443855446d8a647f24fffa6d638": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "df66cab4aba34abcbe6c4c619a97dfd5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e044648d8b4049e5891270a857a5dab5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a0d6db19aab48aea89a09fafbd383d5",
        "IPY_MODEL_046e382efe294995a35d1de25e04c344",
        "IPY_MODEL_6e03882ef4614aceafd78c15b515f5d1"
       ],
       "layout": "IPY_MODEL_6bfcf6d1a06149d8abc77a7feb5fef5d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e1d1c03e36fa491c8bfa8993ff2b24e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3c80b869dff143f3ab0d43dc5d15ef69",
        "IPY_MODEL_6805335b95ef4270bd03530c4259564f",
        "IPY_MODEL_431c8b55788e4bdb998f0c81dd452b99"
       ],
       "layout": "IPY_MODEL_df66cab4aba34abcbe6c4c619a97dfd5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e57e455270ea4775ad097c6f457aef48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e8e4e8fba8834338a940ae5c2c131986": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a42ee61ccdab41dd9ba7c8cef97952bf",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_45183b8174854ea381ddbd2783bed6d4",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:‚Äá100%"
      }
     },
     "ea6852d9f6254550973b7fea85270364": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eaf7bde72e224e3f84973815a7ffd9f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ecd1f6d75cb54f59ab758c3ef75c567a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f01f5806e00542339f5d8f3910bf85bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b5d168b27160461f9976d1e5fb424210",
       "max": 647693783.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7d09ce8b922846799fa739ee84a5a65d",
       "tabbable": null,
       "tooltip": null,
       "value": 647693783.0
      }
     },
     "f10cef5ba69e43ebb220fa310fd2f14b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f254eec4189c4dee9694f39577a1c48a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fab372f4b6b64e22b08772b29b476da5",
        "IPY_MODEL_bea1a7fd33394e3bb48d1225151630ee",
        "IPY_MODEL_2f713da372d8416a8d28d8679243adb4"
       ],
       "layout": "IPY_MODEL_7e46c0aa748546429841ebfe85388605",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f6103646931b4255888d0e285fdd18be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f62b2cbf480a42cfa3685375e2e0fe9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6d4f2f73dee4beeb6bdd17aca293e13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8fc74ef127944a3ac09a4ff72eea19a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f90cb09c7ada486f875a4abd1afbb0fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6cf53cc423a3465089de20006956d898",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d8d8742d9eec4635b5d386e5d00e7c50",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:‚Äá100%"
      }
     },
     "f92bd864fe5f4427b9b740e4607d224c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f98974263b804838aeb5c7d06e4de313": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fab372f4b6b64e22b08772b29b476da5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_382b93fc11394883a3d31457ce683504",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_4ea091885392437ab03b63d376590fd0",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:‚Äá100%"
      }
     },
     "fab94765139b44a79005106124a82611": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fc6b7ec93929429eb3cc8d8a95223920": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd063f0bc3d441a8bca0497f408ce64e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cf6517c3885a4f51bc1611b5d6fe7438",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_5bc4dbee47b846e2a716afe19eae2b89",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:‚Äá100%"
      }
     },
     "ff21f4a56d274e598507ba25af0d1719": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5fc62f2edc93491c85de9a9a24e61a21",
       "max": 772.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_11478a30df5040008d98496a701bab82",
       "tabbable": null,
       "tooltip": null,
       "value": 772.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
